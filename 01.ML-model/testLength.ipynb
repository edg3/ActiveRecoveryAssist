{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class TestProofOfConcept(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = AutoModelForCausalLM.from_pretrained('gpt2').to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "        self.input_text = 'Im not having a great day, I did my exercises, and suggested theropy, but now Im bored. What can I try out that can engage my mind, and keep me entertained?'\n",
    "        self.input_ids = self.tokenizer(self.input_text, return_tensors='pt').input_ids.to(self.device)\n",
    "\n",
    "    def test_generated_ids_is_tensor(self):\n",
    "        generated_ids = self.model.generate(self.input_ids, max_length=1024)\n",
    "        self.assertIsInstance(generated_ids, torch.Tensor)\n",
    "\n",
    "    def test_generated_ids_shape(self):\n",
    "        generated_ids = self.model.generate(self.input_ids, max_length=1024)\n",
    "        self.assertEqual(len(generated_ids.shape), 2)\n",
    "\n",
    "    def test_generated_ids_not_empty(self):\n",
    "        generated_ids = self.model.generate(self.input_ids, max_length=1024)\n",
    "        self.assertGreater(generated_ids.numel(), 0)\n",
    "\n",
    "    def test_generate_called_with_correct_parameters(self):\n",
    "        with unittest.mock.patch.object(self.model, 'generate', wraps=self.model.generate) as mock_generate:\n",
    "            self.model.generate(self.input_ids, max_length=1024)\n",
    "            mock_generate.assert_called_once_with(self.input_ids, max_length=1024)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
