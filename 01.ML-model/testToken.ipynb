{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TestProofOfConcept(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "    def test_model_loaded(self):\n",
    "        self.assertIsNotNone(self.model, \"Model should be loaded\")\n",
    "\n",
    "    def test_tokenizer_loaded(self):\n",
    "        self.assertIsNotNone(self.tokenizer, \"Tokenizer should be loaded\")\n",
    "\n",
    "    def test_model_device(self):\n",
    "        self.assertEqual(next(self.model.parameters()).device, device, \"Model should be on the correct device\")\n",
    "\n",
    "    def test_tokenizer_functionality(self):\n",
    "        sample_text = \"Hello, how are you?\"\n",
    "        tokens = self.tokenizer.encode(sample_text)\n",
    "        self.assertIsInstance(tokens, list, \"Tokenizer should return a list of tokens\")\n",
    "        self.assertGreater(len(tokens), 0, \"Token list should not be empty\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
